{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DC_GAN_AND_.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsxarw42DA72"
      },
      "source": [
        "# 1. Khai báo các thư viện sử dụng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fninAkYrDBBH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyUmfF8dC9Os"
      },
      "source": [
        "import argparse\n",
        "import datetime\n",
        "import glob\n",
        "import itertools\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "\n",
        "import PIL\n",
        "import cv2\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import natsort\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.utils import save_image\n",
        "from numpy import linspace\n",
        "import torchvision\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
        "\n",
        "! pip install config\n",
        "import config\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YSM6Ty5D4eJ"
      },
      "source": [
        "# 2. Định nghĩa mô hình"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdBxqDIxgDI7"
      },
      "source": [
        "\"\"\"\n",
        "Thay vì sử dụng mạng MLP như các thực nghiệm khác thì ở đây sử dụng mạng CNN\n",
        "\"\"\"\n",
        "class NetG_MNIST(nn.Module):\n",
        "    def __init__(self, latent_dim, image_shape, feature_size=64):\n",
        "        super(NetG_MNIST, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.image_shape = image_shape\n",
        "        self.feature_size = feature_size\n",
        "        \n",
        "        self.deconv1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.latent_dim, self.feature_size * 4,\n",
        "                               kernel_size=4, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(self.feature_size * 4),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        self.deconv2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.feature_size * 4, self.feature_size * 2,\n",
        "                               kernel_size=3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(self.feature_size * 2),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        self.deconv3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.feature_size * 2, self.feature_size,\n",
        "                               kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(self.feature_size),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        self.deconv4 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.feature_size, self.image_shape[0],\n",
        "                               kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = z.view(z.shape[0], z.shape[1], 1, 1)\n",
        "        out = self.deconv1(z)\n",
        "        out = self.deconv2(out)\n",
        "        out = self.deconv3(out)\n",
        "        out = self.deconv4(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class NetD_MNIST(nn.Module):\n",
        "    def __init__(self, image_shape, feature_size, loss_function=\"mse\"):\n",
        "        super(NetD_MNIST, self).__init__()\n",
        "        self.image_shape = image_shape\n",
        "        self.feature_size = feature_size\n",
        "        self.loss_function = loss_function\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(self.image_shape[0], self.feature_size,\n",
        "                      kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(self.feature_size, self.feature_size * 2,\n",
        "                      kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(self.feature_size * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(self.feature_size * 2, self.feature_size * 4,\n",
        "                      kernel_size=3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(self.feature_size * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(self.feature_size * 4, 1,\n",
        "                      kernel_size=4, stride=1, padding=0, bias=False),\n",
        "            # nn.Sigmoid(),\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, img):\n",
        "        out = self.conv1(img)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        if self.loss_function == \"bce\":\n",
        "            out = self.sigmoid(out)\n",
        "        return out.view(-1, 1)\n",
        "\n",
        "\n",
        "def test_MNIST():\n",
        "    z = torch.randn(128, 100)\n",
        "    G = NetG_MNIST(latent_dim=100, image_shape=(1, 28, 28), feature_size=64)\n",
        "    # img = torch.randn(128, 1, 28, 28)\n",
        "    D = NetD_MNIST(image_shape=(1, 28, 28), feature_size=64, loss_function=\"bce\")\n",
        "    print(G(z).shape)\n",
        "    print(D(G(z)).shape)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  test_MNIST()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZnxcMENYHTI"
      },
      "source": [
        "# Khởi tạo các tham số \n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        # Fills the input Tensor with values drawn from the normal distribution \\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std  2  )\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        # Fills the input Tensor with the value \\text{val}val.\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "\n",
        "def generate_images(epoch, path, fixed_noise, num_test_samples, netG, device, use_fixed=False):\n",
        "    z = torch.randn(num_test_samples, 100, 1, 1, device=device)\n",
        "    size_figure_grid = int(math.sqrt(num_test_samples))\n",
        "    title = None\n",
        "\n",
        "    if use_fixed:\n",
        "        generated_fake_images = netG(fixed_noise)\n",
        "        path += 'fixed_noise/'\n",
        "        title = 'Fixed Noise'\n",
        "    else:\n",
        "        generated_fake_images = netG(z)\n",
        "        path += 'variable_noise/'\n",
        "        title = 'Variable Noise'\n",
        "\n",
        "    fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(6, 6))\n",
        "    for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
        "        ax[i, j].get_xaxis().set_visible(False)\n",
        "        ax[i, j].get_yaxis().set_visible(False)\n",
        "    for k in range(num_test_samples):\n",
        "        i = k // 4\n",
        "        j = k % 4\n",
        "        ax[i, j].cla()\n",
        "        ax[i, j].imshow(generated_fake_images[k].data.cpu().numpy().reshape(28, 28), cmap='Greys')\n",
        "    label = 'Epoch_{}'.format(epoch + 1)\n",
        "    fig.text(0.5, 0.04, label, ha='center')\n",
        "    fig.suptitle(title)\n",
        "    fig.savefig(path + label + '.png')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtyaoa7vYuZR"
      },
      "source": [
        "# import preprocess_data\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "\n",
        "def generate_dataloader(name_dataset, img_size, batch_size):\n",
        "    # Configure data loader\n",
        "\n",
        "    # MNIST\n",
        "    # Image size: (1, 28, 28)\n",
        "    if name_dataset == 'mnist':\n",
        "        os.makedirs('../datasets/mnist', exist_ok=True)\n",
        "\n",
        "        dataloader_mnist = torch.utils.data.DataLoader(\n",
        "            datasets.MNIST(\n",
        "                '../datasets/mnist',\n",
        "                train=True,\n",
        "                download=True,\n",
        "                transform=transforms.Compose(\n",
        "                    [\n",
        "                        transforms.Resize(img_size),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize([0.5], [0.5])\n",
        "                    ]\n",
        "                ),\n",
        "            ),\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=8,\n",
        "        )\n",
        "        return dataloader_mnist\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlaVjeYMZS0j"
      },
      "source": [
        "# Set random seed for reproducibility\n",
        "manualSeed = 999\n",
        "# manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "\n",
        "def get_noise(n_samples, z_dim):\n",
        "    return torch.randn(n_samples, z_dim, device=device)\n",
        "\n",
        "\n",
        "\n",
        "def show_tensor_images(image_tensor, writer, type_image, step, num_images=25):\n",
        "    \"\"\"\n",
        "    Function for visualizing images: Given a tensor of images, number of images, and\n",
        "    size per image, plots and prints the images in an uniform grid.\n",
        "    \"\"\"\n",
        "    image_tensor = (image_tensor + 1) / 2\n",
        "    image_unflatt = image_tensor.detach().cpu()\n",
        "    image_grid = make_grid(image_unflatt[:num_images], nrow=5, normalize=True)\n",
        "    # show images\n",
        "    # matplotlib_imshow(image_grid, one_channel=True)\n",
        "    # add tensorboard\n",
        "    writer.add_image(type_image, image_grid, global_step=step)\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--n_epochs\", type=int, default=20,\n",
        "                        help=\"number of epochs of training\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=128,\n",
        "                        help=\"size of the batches\")\n",
        "\n",
        "    parser.add_argument(\"--lr\", type=float, default=0.0002,\n",
        "                        help=\"adam: learning rate\")\n",
        "    parser.add_argument(\"--b1\", type=float, default=0.5,\n",
        "                        help=\"adam: decay of first order momentum of gradient\")\n",
        "    parser.add_argument(\"--b2\", type=float, default=0.999,\n",
        "                        help=\"adam: decay of first order momentum of gradient\")\n",
        "    parser.add_argument(\"--n_cpu\", type=int, default=8,\n",
        "                        help=\"number of cpu threads to use during batch generation\")\n",
        "    parser.add_argument(\"--loss_function\", type=str, default=\"mse\",\n",
        "                        help=\"Loss Function\", choices=[\"mse\", \"bce\"])\n",
        "\n",
        "    parser.add_argument(\"--latent_dim\", type=int, default=100,\n",
        "                        help=\"dimensionality of the latent space\")\n",
        "    parser.add_argument(\"--feature_size\", type=int, default=64,\n",
        "                        help=\"dimensionality of the feature\")\n",
        "\n",
        "    parser.add_argument(\"--dataset\", type=str, default=\"mnist\")\n",
        "    parser.add_argument(\"--display_step\", type=int, default=1000,\n",
        "                        help=\"interval between image samples\")\n",
        "    parser.add_argument(\"--save_checkpoint_step\", type=int, default=50000,\n",
        "                        help=\"Saving checkpoint after step\")\n",
        "\n",
        "    parser.add_argument(\"--gpu\", type=str, default='0', help='Specify GPU ')\n",
        "    parser.add_argument('--log_dir', type=str, default=\"dcgan\",\n",
        "                        help='experiment root')\n",
        "    return parser.parse_args(\"\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz_EvheHVPej"
      },
      "source": [
        "\n",
        "global img_size, channels, adversarial_loss, generator, discriminator\n",
        "\n",
        "def log_string(string):\n",
        "    logger.info(string)\n",
        "    print(string)\n",
        "args = parse_args()\n",
        "log_model = args.log_dir + \"_n_epochs_\" + str(args.n_epochs)\n",
        "log_model = log_model + \"_batch_size_\" + str(args.batch_size)\n",
        "log_model = log_model + \"_loss_\" + str(args.loss_function)\n",
        "log_model = log_model + \"_display_step_\" + str(args.display_step)\n",
        "log_model = log_model + \"_\" + args.dataset\n",
        "\n",
        "\n",
        "img_size = 28\n",
        "channels = 1\n",
        "\n",
        "'''CREATE DIR'''\n",
        "time_str = str(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M'))\n",
        "\n",
        "experiment_dir = Path('./log/')\n",
        "experiment_dir.mkdir(exist_ok=True)\n",
        "if args.log_dir is None:\n",
        "    experiment_dir = experiment_dir.joinpath(time_str)\n",
        "else:\n",
        "    experiment_dir = experiment_dir.joinpath(log_model)\n",
        "experiment_dir.mkdir(exist_ok=True)\n",
        "checkpoints_dir = experiment_dir.joinpath('checkpoints/')\n",
        "checkpoints_dir.mkdir(exist_ok=True)\n",
        "\n",
        "log_dir = experiment_dir.joinpath('logs/')\n",
        "log_dir.mkdir(exist_ok=True)\n",
        "\n",
        "'''LOG'''\n",
        "logger = logging.getLogger(\"Model\")\n",
        "logger.setLevel(logging.INFO)\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "file_handler = logging.FileHandler('%s/%s.txt' % (log_dir, \"log\"))\n",
        "file_handler.setLevel(logging.INFO)\n",
        "file_handler.setFormatter(formatter)\n",
        "logger.addHandler(file_handler)\n",
        "\n",
        "log_string(args)\n",
        "log_string(log_model)\n",
        "\n",
        "'''TENSORBROAD'''\n",
        "log_string('Creating Tensorboard ...')\n",
        "tensor_dir = experiment_dir.joinpath('tensorboard/')\n",
        "if tensor_dir.exists():\n",
        "    shutil.rmtree(tensor_dir)\n",
        "tensor_dir.mkdir(exist_ok=True)\n",
        "summary_writer = SummaryWriter(os.path.join(tensor_dir))\n",
        "\n",
        "# GPU Indicator\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "\n",
        "# Save generated images\n",
        "saved_path = experiment_dir.joinpath('images/')\n",
        "os.makedirs(saved_path, exist_ok=True)\n",
        "\n",
        "# Configure data loader\n",
        "dataloader = generate_dataloader(\n",
        "    name_dataset=args.dataset,\n",
        "    img_size=img_size,\n",
        "    batch_size=args.batch_size\n",
        ")\n",
        "\n",
        "# Loss functions\n",
        "if args.loss_function == \"bce\":\n",
        "    adversarial_loss = torch.nn.BCELoss()\n",
        "elif args.loss_function == \"mse\":\n",
        "    adversarial_loss = torch.nn.MSELoss()\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "\n",
        "\n",
        "    generator = NetG_MNIST(\n",
        "        latent_dim=args.latent_dim,\n",
        "        image_shape=(channels, img_size, img_size),\n",
        "        feature_size=args.feature_size\n",
        "    )\n",
        "    discriminator = NetD_MNIST(\n",
        "        image_shape=(channels, img_size, img_size),\n",
        "        feature_size=args.feature_size,\n",
        "        loss_function=args.loss_function\n",
        "    )\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=args.lr, betas=(args.b1, args.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=args.lr, betas=(args.b1, args.b2))\n",
        "\n",
        "# Assign device for model, criterion\n",
        "generator.to(device)\n",
        "discriminator.to(device)\n",
        "adversarial_loss.to(device)\n",
        "\n",
        "# Initialize weights\n",
        "generator.apply(weights_init)\n",
        "discriminator.apply(weights_init)\n",
        "\n",
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "log_string(\"Starting Training Loop...\")\n",
        "\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "fixed_noise = torch.randn(args.batch_size, args.latent_dim, device=device)\n",
        "\n",
        "wrapper = torch.nn.Sequential(generator, discriminator)\n",
        "\n",
        "summary_writer.add_graph(wrapper, input_to_model=torch.randn(1, args.latent_dim).to(device))\n",
        "\n",
        "for epoch in range(args.n_epochs):\n",
        "    for i, (images, _) in enumerate(dataloader):\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        real_label = 1.\n",
        "        fake_label = 0.\n",
        "\n",
        "        # Configure input\n",
        "        label = torch.full((images.size(0), 1), real_label, dtype=torch.float, device=device)\n",
        "        real_images = images.to(device)\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "\n",
        "        # Train with all-real batch\n",
        "\n",
        "        discriminator.zero_grad()\n",
        "        output = discriminator(real_images)\n",
        "\n",
        "        errD_real = adversarial_loss(output, label)\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        # Train with all-fake batch\n",
        "        # Generate batch of latent vectors\n",
        "        noise = torch.randn(images.size(0), args.latent_dim, device=device)\n",
        "\n",
        "        gen_images = generator(noise)\n",
        "        \n",
        "        label.fill_(fake_label)\n",
        "        # Classify all fake batch with D\n",
        "        output = discriminator(gen_images.detach())\n",
        "        # Calculate D's loss on the all-fake batch\n",
        "        errD_fake = adversarial_loss(output, label)\n",
        "        errD_fake.backward()\n",
        "        # Add the gradients from the all-real and all-fake batches\n",
        "        errD = (errD_real + errD_fake) / 2\n",
        "        D_G_z1_tensor = output\n",
        "        D_G_z1 = output.mean().item()\n",
        "        # Update D\n",
        "        optimizer_D.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "\n",
        "        generator.zero_grad()\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        label.fill_(real_label)\n",
        "        output = discriminator(gen_images)\n",
        "        # Calculate G's loss based on this output\n",
        "        errG = adversarial_loss(output, label)\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "        D_G_z2_tensor = output\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # Update G\n",
        "        optimizer_G.step()\n",
        "\n",
        "        if i % 22 == 0:\n",
        "            log_string(\n",
        "                \"[Epoch %d/%d] [Batch %d/%d]\"\n",
        "                \"\\t[Loss_D: %.4f]\\t[Loss_G: %.4f]\\t[D(x): %.4f]\\t[D(G(z)): %.4f / %.4f]\"\n",
        "                % (epoch, args.n_epochs, i, len(dataloader),\n",
        "                    errD.item(), errG.item(), D_x, D_G_z1, D_G_z2)\n",
        "            )\n",
        "\n",
        "        D_losses.append(errD.item())\n",
        "        G_losses.append(errG.item())\n",
        "\n",
        "        steps = epoch * len(dataloader) + i\n",
        "        summary_writer.add_scalars(\n",
        "            'Loss',\n",
        "            {\n",
        "                'D': errD.item(),\n",
        "                'G': errG.item()\n",
        "            },\n",
        "            steps\n",
        "        )\n",
        "        summary_writer.add_scalar('D(x)', D_x, steps)\n",
        "        summary_writer.add_scalar('D(G(z1))', D_G_z1, steps)\n",
        "        summary_writer.add_scalar('D(G(z2))', D_G_z2, steps)\n",
        "\n",
        "        if steps % args.display_step == 0:\n",
        "            with torch.no_grad():\n",
        "                fake = generator(fixed_noise)\n",
        "\n",
        "\n",
        "                # save_image(real_images.data[:25], saved_path.joinpath(\"real_%d.png\" % steps),\n",
        "                #            nrow=5, normalize=True)\n",
        "                save_image(fake.data[:25], saved_path.joinpath(\"%d.png\" % steps),\n",
        "                            nrow=5, normalize=True)\n",
        "\n",
        "                show_tensor_images(fake, summary_writer, \"Fake Image\", steps)\n",
        "                show_tensor_images(real_images, summary_writer, \"Real Image\", steps)\n",
        "\n",
        "    # interpolation giữa 2 samples.\n",
        "    sample_x = torch.randn((100,))\n",
        "    sample_y = torch.randn((100,))\n",
        "\n",
        "    a = torch.Tensor(linspace(sample_x.numpy(), sample_y.numpy(), num=10))\n",
        "    sample_imgs = generator(a)\n",
        "\n",
        "    grid = torchvision.utils.make_grid(sample_imgs, nrow=10)\n",
        "\n",
        "    writer = SummaryWriter(\n",
        "        \"interpolate\"\n",
        "    )\n",
        "    writer.add_image('DCDCGAN interpolation {}'.format(i), grid)\n",
        "    interpolation_result = \"interpolation_result\"\n",
        "    os.makedirs( interpolation_result,exist_ok=True)\n",
        "    vutils.save_image(sample_imgs.data.cpu(), '%s/fake_samples_epoch_%03d.png' % (interpolation_result, i),\n",
        "                          normalize=True)\n",
        "\n",
        "\n",
        "# Plot lossy graph\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses, label=\"Generator\")\n",
        "plt.plot(D_losses, label=\"Discriminator\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig(experiment_dir.joinpath('graph.png'))\n",
        "summary_writer.add_figure(\"Graph Loss\", plt.gcf())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LSpNGYpRWp4"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=/content/log "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hr4BMOvzb3d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}